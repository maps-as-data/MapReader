{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares the patches generated by MapReader with the StopGB dataset\n",
    "\n",
    "* Which Stops from StopGB are or are not within a MapReader Patch?\n",
    "  * If they are which patch ID?\n",
    "\n",
    "For each Stop within StopsGB:\n",
    "  * Is it within a MapReader patch? If so which patch?\n",
    "  * If it is not, is it with a XXX meter buffer of the patches? If so which is the nearest patch centroid?\n",
    "\n",
    "\n",
    "Also:\n",
    "* Can this be used to identify errors in either the StopsGB or MapReader Patch data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gspread\n",
    "# ! pip install df2gspread\n",
    "\n",
    "# ! pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
    "# 'conda install pygeos' or \n",
    "# ! pip install pygeos\n",
    "# ! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas\n",
    "from icecream import ic\n",
    "import pygeos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Taken from https://towardsdatascience.com/how-to-import-google-sheets-data-into-a-pandas-dataframe-using-googles-api-v4-2020-f50e84ea4530\n",
    "\n",
    "# import pickle\n",
    "# import os.path\n",
    "# from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "# from google.auth.transport.requests import Request\n",
    "# from googleapiclient.discovery import build\n",
    "\n",
    "\n",
    "# def gsheet_api_check(SCOPES):\n",
    "#     creds = None\n",
    "#     if os.path.exists('token.pickle'):\n",
    "#         with open('token.pickle', 'rb') as token:\n",
    "#             creds = pickle.load(token)\n",
    "            \n",
    "#     if not creds or not creds.valid:\n",
    "#         if creds and creds.expired and creds.refresh_token:\n",
    "#             creds.refresh(Request())\n",
    "#         else:\n",
    "#             flow = InstalledAppFlow.from_client_secrets_file(\n",
    "#                 'credentials.json', SCOPES)\n",
    "#             creds = flow.run_local_server(port=0)\n",
    "\n",
    "#         with open('token.pickle', 'wb') as token:\n",
    "#             pickle.dump(creds, token)\n",
    "\n",
    "#     return creds\n",
    "\n",
    "\n",
    "# def pull_sheet_data(SCOPES,SPREADSHEET_ID,DATA_TO_PULL):\n",
    "#     creds = gsheet_api_check(SCOPES)\n",
    "#     service = build('sheets', 'v4', credentials=creds)\n",
    "#     sheet = service.spreadsheets()\n",
    "#     result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=DATA_TO_PULL).execute()\n",
    "#     values = result.get('values', [])\n",
    "    \n",
    "#     if not values:\n",
    "#         print('No data found.')\n",
    "#     else:\n",
    "#         rows = sheet.values().get(spreadsheetId=SPREADSHEET_ID,\n",
    "#                                   range=DATA_TO_PULL).execute()\n",
    "#         data = rows.get('values')\n",
    "#         print(\"COMPLETE: Data copied\")\n",
    "#         return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some handly functions for reading and writing to Google Spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some handly functions to wrap up reading and writing to Google Spreadsheets\n",
    "\n",
    "See https://docs.gspread.org/en/latest/index.html for details\n",
    "\"\"\"\n",
    "import os.path\n",
    "import gspread\n",
    "\n",
    "\n",
    "def open_gspreadsheet(gss_url, credentials_fpath=None, authorized_user_fpath=None):\n",
    "    ipynb_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "\n",
    "    if not credentials_fpath:\n",
    "        credentials_fpath = os.path.join(ipynb_path, \"credentials.json\")\n",
    "\n",
    "    if not authorized_user_fpath:\n",
    "        authorized_user_fpath = os.path.join(ipynb_path, \"authorized_user.json\")\n",
    "\n",
    "    gc = gspread.oauth(\n",
    "        credentials_filename=credentials_fpath,\n",
    "        authorized_user_filename=authorized_user_fpath\n",
    "    )\n",
    "\n",
    "    gss = gc.open_by_url(gss_url)\n",
    "    return gss\n",
    "\n",
    "def get_sheet_as_dataframe(gss, sheet_name):\n",
    "    ic([sheet.title for sheet in gss.worksheets()])\n",
    "    sheet = gss.worksheet(sheet_name)\n",
    "    dataframe = pd.DataFrame(sheet.get_all_records())\n",
    "    return dataframe\n",
    "\n",
    "def write_dataframe_to_sheet(dataframe, gss, sheet_name, overwrite_existing_sheet=False):\n",
    "    \"\"\"   \n",
    "    Behaviour in different senarios: \n",
    "        in==T,  ow==T => Del, then create new\n",
    "        in==T,  ow==F => Raise exception\n",
    "        in==F,  ow==T => create new\n",
    "        in==F,  ow==F => create new\n",
    "    \"\"\"\n",
    "    if (sheet_name in [sheet.title for sheet in gss.worksheets()]):\n",
    "        if overwrite_existing_sheet:\n",
    "            old_sheet = gss.worksheet(sheet_name)\n",
    "            gss.del_worksheet(old_sheet)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot overwrite existing sheet '{sheet_name}'. Please use a\"\n",
    "                              \" different `sheet_name` or select `overwrite_existing_sheet=True`\")\n",
    "\n",
    "    # Now create a new sheet\n",
    "    nrows, ncols = dataframe.shape\n",
    "    new_sheet = gss.add_worksheet(sheet_name, rows=nrows, cols=ncols)\n",
    "    # And write out the data frame\n",
    "    new_sheet.update([dataframe.columns.values.tolist()] + dataframe.values.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| stopsgb_gpkg_path: '/Users/a.smith/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/Documents/Living-with-machines/code/MapReader/examples/postproc/stops_gb.gpkg'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Global variables\n",
    "\"\"\"\n",
    "# Testing value:\n",
    "# stopsgb_gss_url = \"https://docs.google.com/spreadsheets/d/1nJpaT_e7dpDkqFLV2nLsnuGHngMKsD-t7vjtepVbfrs/edit#gid=879256170\"\n",
    "# input_sheet_name = \"StopsGB_andy_org\"\n",
    "# \"Real\" value:\n",
    "stopsgb_gss_url = \"https://docs.google.com/spreadsheets/d/1_9-dIJXrLAVEgDKYJe6YQNCQu5rP7eOwPGW6zxydBw4/edit#gid=879256170\"\n",
    "input_sheet_name = \"StopsGB\"\n",
    "\n",
    "output_sheet_name = \"StopsGB_with_patch_info\"\n",
    "\n",
    "ipynb_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "# \"Real\" value:\n",
    "stopsgb_gpkg_path = os.path.join(ipynb_path, \"stops_gb.gpkg\")\n",
    "stopsgb_layer_name = \"joined_stops_gb\"\n",
    "# Temp Stops Exctract for testing\n",
    "# stopsgb_gpkg_path = \"/Users/a.smith/Documents.OLD/Living-with-machines/mapreader_display_data/pred_squares_extract.gpkg\"\n",
    "# stopsgb_layer_name = \"stops_gb_extract\"\n",
    "\n",
    "ic(stopsgb_gpkg_path)\n",
    "\n",
    "# Testing value:\n",
    "# patches_gpkg_path = \"/Users/a.smith/Documents.OLD/Living-with-machines/mapreader_display_data/pred_squares_extract.gpkg\"\n",
    "# patches_layer_name = \"patches_0103_extract\"\n",
    "# \"Real\" value:\n",
    "patches_gpkg_path = \"/Users/a.smith/Documents.OLD/Living-with-machines/mapreader_display_data/pred_squares2.gpkg\"\n",
    "patches_layer_name = \"patches_0103_all_v003\"\n",
    "\n",
    "patch_centroids_path = \"/Users/a.smith/Documents.OLD/Living-with-machines/mapreader_display_data/pred.gpkg\"\n",
    "patch_centroids_layer_name = \"pred_0103_all_v003\"\n",
    "\n",
    "maxium_distance = 2000 # meters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the StopsGB data from a Google Speadsheet into a GeoPKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| [sheet.title for sheet in gss.worksheets()]: ['StopsGB']\n",
      "ic| len(df): 12676\n",
      "ic| len(filtered_df): 12142\n",
      "/usr/local/anaconda3/envs/geo_env/lib/python3.10/site-packages/geopandas/io/file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "ic| len(stops_gb_gdf): 12142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12142"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# Open the Google Spreadsheet\n",
    "gss = open_gspreadsheet(gss_url=stopsgb_gss_url)\n",
    "df = get_sheet_as_dataframe(gss, input_sheet_name)\n",
    "\n",
    "# Filter out \"unknown\" values.\n",
    "ic(len(df))\n",
    "filtered_df = df.loc[(df.selected_entity_longitude != \"unknown\") & (df.selected_entity_latitude != \"unknown\")]\n",
    "ic(len(filtered_df))\n",
    "\n",
    "# Create GeoDF from `selected_entity_latitude` and `selected_entity_longitude` values.\n",
    "source_crs = \"EPSG:4326\"\n",
    "stops_gb_gdf = geopandas.GeoDataFrame(\n",
    "    filtered_df, geometry=geopandas.points_from_xy(filtered_df.selected_entity_longitude, filtered_df.selected_entity_latitude, crs=source_crs))\n",
    "\n",
    "# Write out to GeoPKG\n",
    "stops_gb_gdf.to_file(stopsgb_gpkg_path, driver=\"GPKG\", layer=stopsgb_layer_name)\n",
    "ic(len(stops_gb_gdf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the patches GeoPKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load patches polygons\n",
    "from shapely.geometry.linestring import LineString\n",
    "from pandas import to_numeric, NamedAgg\n",
    "\n",
    "patches_gdf = geopandas.read_file(patches_gpkg_path, layer=patches_layer_name)\n",
    "patch_centroids_gdf = geopandas.read_file(patch_centroids_path, layer=patch_centroids_layer_name)\n",
    "# patch_centroids_gdf.set_crs(\"EPSG:4326\")\n",
    "stops_gb_gdf = geopandas.read_file(stopsgb_gpkg_path, layer=stopsgb_layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the number of Patches containing each Stop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(patch_count_df): 12142\n",
      "ic| patch_count_df.head():            patch_count\n",
      "                           StationId             \n",
      "                           1                    1\n",
      "                           2                    1\n",
      "                           3                    1\n",
      "                           4                    1\n",
      "                           5                    0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate the number of Patches containing each Stop (0,1, or rarely >1) \n",
    "\"\"\"\n",
    "# Convert to common CRS\n",
    "stops_gb_gdf = stops_gb_gdf.to_crs(\"EPSG:3857\")\n",
    "# Join the stops and the patches\n",
    "stops_within_patch_gdf = stops_gb_gdf.sjoin(patches_gdf, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# Drop everything except the station ID and patch ID\n",
    "stops_within_patch_gdf = stops_within_patch_gdf[[\n",
    "    \"StationId\",\n",
    "    \"image_id\",\n",
    "]]\n",
    "\n",
    "# Filter out any cases where there isn't a matching patch ID\n",
    "# NOTE: Turns out that this isn't necessary\n",
    "#Â stops_within_patch_gdf = stops_within_patch_gdf.loc[lambda stops_within_patch_gdf: ~stops_within_patch_gdf[\"image_id\"].isna(), :]\n",
    "# ic(stops_within_patch_gdf)\n",
    "\n",
    "# Group by to get cases where there is more than one patch per stop.\n",
    "groupby_station_id_df = stops_within_patch_gdf.groupby(by=\"StationId\")\n",
    "patch_count_df = groupby_station_id_df.agg(patch_count=NamedAgg(column=\"image_id\", aggfunc=\"count\"))\n",
    "ic(len(patch_count_df))\n",
    "ic(patch_count_df.head())\n",
    "\n",
    "# Now join \"patch_count\" column back into StopsGB\n",
    "stops_within_patch_gdf = stops_gb_gdf.join(patch_count_df, how=\"left\", on=\"StationId\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the closest patches centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| nearest_gdf['distance_to_patch_centroid'].describe(): count     12323\n",
      "                                                          unique     8783\n",
      "                                                          top            \n",
      "                                                          freq        898\n",
      "                                                          Name: distance_to_patch_centroid, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     12323\n",
       "unique     8783\n",
       "top            \n",
       "freq        898\n",
       "Name: distance_to_patch_centroid, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate the closest patches centroid.\n",
    "Add columns for:\n",
    "* PatchID\n",
    "* Distance\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "# Convert to a common CRS\n",
    "patch_centroids_gdf = patch_centroids_gdf.to_crs(\"EPSG:3857\")\n",
    "\n",
    "nearest_gdf = stops_within_patch_gdf.sjoin_nearest(\n",
    "    patch_centroids_gdf,\n",
    "    how=\"left\",\n",
    "    max_distance=maxium_distance,\n",
    "    rsuffix=\"right_\",\n",
    "    distance_col=\"distance_to_patch_centroid\"\n",
    ")\n",
    "\n",
    "nearest_gdf = nearest_gdf.fillna(\"\")\n",
    "# ic(nearest_gdf.head(10))\n",
    "ic(nearest_gdf['distance_to_patch_centroid'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write results back to GSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now write results back to GSS\n",
    "\"\"\"\n",
    "# Exclude geometry column:\n",
    "tempdf = nearest_gdf.loc[:, nearest_gdf.columns!='geometry']\n",
    "write_dataframe_to_sheet(tempdf, gss, output_sheet_name, overwrite_existing_sheet=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa1c5ccde9ae19d59b063d3dd54bf83dcbe3832a796a91bbebc54a3486b1b187"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('geo_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
